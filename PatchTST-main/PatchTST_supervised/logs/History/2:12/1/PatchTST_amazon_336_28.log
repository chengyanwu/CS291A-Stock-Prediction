Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='336_28', model='PatchTST', data='custom', root_path='./dataset/', data_path='AMZN_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=28, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=21, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use CPU
>>>>>>>start training : 336_28_PatchTST_custom_ftM_sl336_ll48_pl28_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 518
val 100
test 224
Epoch: 1 cost time: 38.07700204849243
Epoch: 1, Steps: 4 | Train Loss: 1.1262407 Vali Loss: nan Test Loss: 1.7802763
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 31.741200923919678
Epoch: 2, Steps: 4 | Train Loss: 0.9056829 Vali Loss: nan Test Loss: 0.7284281
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 32.043298959732056
Epoch: 3, Steps: 4 | Train Loss: 0.6009948 Vali Loss: nan Test Loss: 0.2497081
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 32.430107831954956
Epoch: 4, Steps: 4 | Train Loss: 0.6161383 Vali Loss: nan Test Loss: 0.2033564
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 31.79600429534912
Epoch: 5, Steps: 4 | Train Loss: 0.6445295 Vali Loss: nan Test Loss: 0.2141650
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 31.424667835235596
Epoch: 6, Steps: 4 | Train Loss: 0.5768390 Vali Loss: nan Test Loss: 0.2352253
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 31.60256004333496
Epoch: 7, Steps: 4 | Train Loss: 0.4901092 Vali Loss: nan Test Loss: 0.2990725
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 31.264266967773438
Epoch: 8, Steps: 4 | Train Loss: 0.4480668 Vali Loss: nan Test Loss: 0.3796237
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 31.714925050735474
Epoch: 9, Steps: 4 | Train Loss: 0.4348356 Vali Loss: nan Test Loss: 0.4383634
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 31.29049587249756
Epoch: 10, Steps: 4 | Train Loss: 0.4215536 Vali Loss: nan Test Loss: 0.4550273
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 32.7496120929718
Epoch: 11, Steps: 4 | Train Loss: 0.4104266 Vali Loss: nan Test Loss: 0.4380779
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 31.81123185157776
Epoch: 12, Steps: 4 | Train Loss: 0.4002033 Vali Loss: nan Test Loss: 0.4055161
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 31.547019004821777
Epoch: 13, Steps: 4 | Train Loss: 0.3902174 Vali Loss: nan Test Loss: 0.3673074
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 31.830840826034546
Epoch: 14, Steps: 4 | Train Loss: 0.3760386 Vali Loss: nan Test Loss: 0.3340213
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 31.827047109603882
Epoch: 15, Steps: 4 | Train Loss: 0.3688859 Vali Loss: nan Test Loss: 0.3079247
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 34.30598330497742
Epoch: 16, Steps: 4 | Train Loss: 0.3580168 Vali Loss: nan Test Loss: 0.2884919
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 34.41966700553894
Epoch: 17, Steps: 4 | Train Loss: 0.3514141 Vali Loss: nan Test Loss: 0.2741845
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 33.595282793045044
Epoch: 18, Steps: 4 | Train Loss: 0.3511294 Vali Loss: nan Test Loss: 0.2643844
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 33.753499031066895
Epoch: 19, Steps: 4 | Train Loss: 0.3458958 Vali Loss: nan Test Loss: 0.2582159
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 34.1873939037323
Epoch: 20, Steps: 4 | Train Loss: 0.3392513 Vali Loss: nan Test Loss: 0.2547958
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 34.47120118141174
Epoch: 21, Steps: 4 | Train Loss: 0.3375565 Vali Loss: nan Test Loss: 0.2534676
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 33.883455991744995
Epoch: 22, Steps: 4 | Train Loss: 0.3349081 Vali Loss: nan Test Loss: 0.2537529
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 35.062636613845825
Epoch: 23, Steps: 4 | Train Loss: 0.3326708 Vali Loss: nan Test Loss: 0.2542080
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 34.373242139816284
Epoch: 24, Steps: 4 | Train Loss: 0.3305542 Vali Loss: nan Test Loss: 0.2553661
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 34.485954999923706
Epoch: 25, Steps: 4 | Train Loss: 0.3280573 Vali Loss: nan Test Loss: 0.2565195
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 33.278645038604736
Epoch: 26, Steps: 4 | Train Loss: 0.3278005 Vali Loss: nan Test Loss: 0.2577688
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 34.185648918151855
Epoch: 27, Steps: 4 | Train Loss: 0.3276601 Vali Loss: nan Test Loss: 0.2586944
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 33.25357627868652
Epoch: 28, Steps: 4 | Train Loss: 0.3224924 Vali Loss: nan Test Loss: 0.2592651
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 38.62796473503113
Epoch: 29, Steps: 4 | Train Loss: 0.3203637 Vali Loss: nan Test Loss: 0.2596918
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 100.10888814926147
Epoch: 30, Steps: 4 | Train Loss: 0.3212657 Vali Loss: nan Test Loss: 0.2600493
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 34.425392866134644
Epoch: 31, Steps: 4 | Train Loss: 0.3204628 Vali Loss: nan Test Loss: 0.2600788
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 33.82324719429016
Epoch: 32, Steps: 4 | Train Loss: 0.3171393 Vali Loss: nan Test Loss: 0.2599765
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 33.249632835388184
Epoch: 33, Steps: 4 | Train Loss: 0.3162616 Vali Loss: nan Test Loss: 0.2597663
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 33.849589109420776
Epoch: 34, Steps: 4 | Train Loss: 0.3168871 Vali Loss: nan Test Loss: 0.2593474
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 33.88824200630188
Epoch: 35, Steps: 4 | Train Loss: 0.3164077 Vali Loss: nan Test Loss: 0.2591324
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 33.44978666305542
Epoch: 36, Steps: 4 | Train Loss: 0.3160824 Vali Loss: nan Test Loss: 0.2586832
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 34.35741686820984
Epoch: 37, Steps: 4 | Train Loss: 0.3168952 Vali Loss: nan Test Loss: 0.2584497
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 33.43086624145508
Epoch: 38, Steps: 4 | Train Loss: 0.3159089 Vali Loss: nan Test Loss: 0.2582907
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 34.81112504005432
Epoch: 39, Steps: 4 | Train Loss: 0.3147612 Vali Loss: nan Test Loss: 0.2580536
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 33.04793381690979
Epoch: 40, Steps: 4 | Train Loss: 0.3173061 Vali Loss: nan Test Loss: 0.2579218
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0275559590445276e-06
Epoch: 41 cost time: 37.41523289680481
Epoch: 41, Steps: 4 | Train Loss: 0.3123759 Vali Loss: nan Test Loss: 0.2578015
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8248003631400751e-06
Epoch: 42 cost time: 34.06082081794739
Epoch: 42, Steps: 4 | Train Loss: 0.3147107 Vali Loss: nan Test Loss: 0.2575607
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6423203268260676e-06
Epoch: 43 cost time: 34.03857898712158
Epoch: 43, Steps: 4 | Train Loss: 0.3118521 Vali Loss: nan Test Loss: 0.2574051
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4780882941434609e-06
Epoch: 44 cost time: 34.22609901428223
Epoch: 44, Steps: 4 | Train Loss: 0.3129825 Vali Loss: nan Test Loss: 0.2573843
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3302794647291146e-06
Epoch: 45 cost time: 34.70290493965149
Epoch: 45, Steps: 4 | Train Loss: 0.3128269 Vali Loss: nan Test Loss: 0.2571230
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1972515182562034e-06
Epoch: 46 cost time: 35.696747064590454
Epoch: 46, Steps: 4 | Train Loss: 0.3146789 Vali Loss: nan Test Loss: 0.2570461
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.077526366430583e-06
Epoch: 47 cost time: 35.05383086204529
Epoch: 47, Steps: 4 | Train Loss: 0.3100382 Vali Loss: nan Test Loss: 0.2568438
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.697737297875248e-07
Epoch: 48 cost time: 34.728508949279785
Epoch: 48, Steps: 4 | Train Loss: 0.3134912 Vali Loss: nan Test Loss: 0.2567991
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.727963568087723e-07
Epoch: 49 cost time: 35.400310039520264
Epoch: 49, Steps: 4 | Train Loss: 0.3134520 Vali Loss: nan Test Loss: 0.2567532
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.855167211278951e-07
Epoch: 50 cost time: 38.2088840007782
Epoch: 50, Steps: 4 | Train Loss: 0.3112302 Vali Loss: nan Test Loss: 0.2567525
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.069650490151056e-07
Epoch: 51 cost time: 35.197998046875
Epoch: 51, Steps: 4 | Train Loss: 0.3112453 Vali Loss: nan Test Loss: 0.2566334
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.36268544113595e-07
Epoch: 52 cost time: 36.48588514328003
Epoch: 52, Steps: 4 | Train Loss: 0.3124890 Vali Loss: nan Test Loss: 0.2566701
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.726416897022355e-07
Epoch: 53 cost time: 36.183253049850464
Epoch: 53, Steps: 4 | Train Loss: 0.3130778 Vali Loss: nan Test Loss: 0.2565947
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.15377520732012e-07
Epoch: 54 cost time: 34.61942505836487
Epoch: 54, Steps: 4 | Train Loss: 0.3100906 Vali Loss: nan Test Loss: 0.2564167
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.6383976865881085e-07
Epoch: 55 cost time: 33.7872040271759
Epoch: 55, Steps: 4 | Train Loss: 0.3138597 Vali Loss: nan Test Loss: 0.2563450
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.174557917929298e-07
Epoch: 56 cost time: 33.89682602882385
Epoch: 56, Steps: 4 | Train Loss: 0.3104029 Vali Loss: nan Test Loss: 0.2563170
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.7571021261363677e-07
Epoch: 57 cost time: 35.59238600730896
Epoch: 57, Steps: 4 | Train Loss: 0.3114699 Vali Loss: nan Test Loss: 0.2562728
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.381391913522731e-07
Epoch: 58 cost time: 33.96669578552246
Epoch: 58, Steps: 4 | Train Loss: 0.3117023 Vali Loss: nan Test Loss: 0.2563269
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.043252722170458e-07
Epoch: 59 cost time: 36.87531900405884
Epoch: 59, Steps: 4 | Train Loss: 0.3127242 Vali Loss: nan Test Loss: 0.2562866
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.7389274499534124e-07
Epoch: 60 cost time: 36.79925179481506
Epoch: 60, Steps: 4 | Train Loss: 0.3130870 Vali Loss: nan Test Loss: 0.2562000
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.465034704958071e-07
Epoch: 61 cost time: 34.892191886901855
Epoch: 61, Steps: 4 | Train Loss: 0.3124910 Vali Loss: nan Test Loss: 0.2560885
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.218531234462264e-07
Epoch: 62 cost time: 34.93347907066345
Epoch: 62, Steps: 4 | Train Loss: 0.3109525 Vali Loss: nan Test Loss: 0.2560899
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9966781110160376e-07
Epoch: 63 cost time: 35.65675592422485
Epoch: 63, Steps: 4 | Train Loss: 0.3107243 Vali Loss: nan Test Loss: 0.2561923
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.797010299914434e-07
Epoch: 64 cost time: 33.3917019367218
Epoch: 64, Steps: 4 | Train Loss: 0.3112564 Vali Loss: nan Test Loss: 0.2561643
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6173092699229907e-07
Epoch: 65 cost time: 38.88030409812927
Epoch: 65, Steps: 4 | Train Loss: 0.3120084 Vali Loss: nan Test Loss: 0.2562772
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4555783429306916e-07
Epoch: 66 cost time: 32.77440810203552
Epoch: 66, Steps: 4 | Train Loss: 0.3154716 Vali Loss: nan Test Loss: 0.2562437
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3100205086376224e-07
Epoch: 67 cost time: 33.31754112243652
Epoch: 67, Steps: 4 | Train Loss: 0.3110784 Vali Loss: nan Test Loss: 0.2562603
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.1790184577738603e-07
Epoch: 68 cost time: 33.196566581726074
Epoch: 68, Steps: 4 | Train Loss: 0.3147104 Vali Loss: nan Test Loss: 0.2562546
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0611166119964742e-07
Epoch: 69 cost time: 37.5025110244751
Epoch: 69, Steps: 4 | Train Loss: 0.3137659 Vali Loss: nan Test Loss: 0.2561228
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.550049507968268e-08
Epoch: 70 cost time: 33.355918169021606
Epoch: 70, Steps: 4 | Train Loss: 0.3144386 Vali Loss: nan Test Loss: 0.2562121
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.595044557171442e-08
Epoch: 71 cost time: 33.185892820358276
Epoch: 71, Steps: 4 | Train Loss: 0.3096893 Vali Loss: nan Test Loss: 0.2561933
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.735540101454298e-08
Epoch: 72 cost time: 33.185105085372925
Epoch: 72, Steps: 4 | Train Loss: 0.3109608 Vali Loss: nan Test Loss: 0.2561789
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.961986091308869e-08
Epoch: 73 cost time: 32.76324200630188
Epoch: 73, Steps: 4 | Train Loss: 0.3155382 Vali Loss: nan Test Loss: 0.2562389
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.265787482177981e-08
Epoch: 74 cost time: 33.40315222740173
Epoch: 74, Steps: 4 | Train Loss: 0.3107172 Vali Loss: nan Test Loss: 0.2562355
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.639208733960184e-08
Epoch: 75 cost time: 35.00597882270813
Epoch: 75, Steps: 4 | Train Loss: 0.3104031 Vali Loss: nan Test Loss: 0.2562107
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.075287860564165e-08
Epoch: 76 cost time: 35.410390853881836
Epoch: 76, Steps: 4 | Train Loss: 0.3085045 Vali Loss: nan Test Loss: 0.2561899
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.567759074507749e-08
Epoch: 77 cost time: 33.146806955337524
Epoch: 77, Steps: 4 | Train Loss: 0.3134621 Vali Loss: nan Test Loss: 0.2561484
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.1109831670569744e-08
Epoch: 78 cost time: 32.402403116226196
Epoch: 78, Steps: 4 | Train Loss: 0.3090262 Vali Loss: nan Test Loss: 0.2561786
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.6998848503512764e-08
Epoch: 79 cost time: 33.21258616447449
Epoch: 79, Steps: 4 | Train Loss: 0.3100984 Vali Loss: nan Test Loss: 0.2560962
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.3298963653161496e-08
Epoch: 80 cost time: 33.55175018310547
Epoch: 80, Steps: 4 | Train Loss: 0.3131131 Vali Loss: nan Test Loss: 0.2560821
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.996906728784534e-08
Epoch: 81 cost time: 32.80772018432617
Epoch: 81, Steps: 4 | Train Loss: 0.3116755 Vali Loss: nan Test Loss: 0.2560347
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.697216055906081e-08
Epoch: 82 cost time: 33.220627784729004
Epoch: 82, Steps: 4 | Train Loss: 0.3111477 Vali Loss: nan Test Loss: 0.2560587
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.427494450315473e-08
Epoch: 83 cost time: 34.444117069244385
Epoch: 83, Steps: 4 | Train Loss: 0.3133087 Vali Loss: nan Test Loss: 0.2559601
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.1847450052839257e-08
Epoch: 84 cost time: 33.85547184944153
Epoch: 84, Steps: 4 | Train Loss: 0.3118058 Vali Loss: nan Test Loss: 0.2560120
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.9662705047555332e-08
Epoch: 85 cost time: 33.530086040496826
Epoch: 85, Steps: 4 | Train Loss: 0.3104019 Vali Loss: nan Test Loss: 0.2559466
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.7696434542799797e-08
Epoch: 86 cost time: 32.35648989677429
Epoch: 86, Steps: 4 | Train Loss: 0.3141385 Vali Loss: nan Test Loss: 0.2560628
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5926791088519817e-08
Epoch: 87 cost time: 33.14130091667175
Epoch: 87, Steps: 4 | Train Loss: 0.3115838 Vali Loss: nan Test Loss: 0.2559800
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.4334111979667836e-08
Epoch: 88 cost time: 34.338632106781006
Epoch: 88, Steps: 4 | Train Loss: 0.3087506 Vali Loss: nan Test Loss: 0.2559831
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2900700781701054e-08
Epoch: 89 cost time: 32.15620803833008
Epoch: 89, Steps: 4 | Train Loss: 0.3114343 Vali Loss: nan Test Loss: 0.2560846
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.161063070353095e-08
Epoch: 90 cost time: 32.798542976379395
Epoch: 90, Steps: 4 | Train Loss: 0.3153232 Vali Loss: nan Test Loss: 0.2561489
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0449567633177854e-08
Epoch: 91 cost time: 33.185709953308105
Epoch: 91, Steps: 4 | Train Loss: 0.3117707 Vali Loss: nan Test Loss: 0.2560674
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.404610869860069e-09
Epoch: 92 cost time: 32.881818771362305
Epoch: 92, Steps: 4 | Train Loss: 0.3119789 Vali Loss: nan Test Loss: 0.2561457
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.464149782874063e-09
Epoch: 93 cost time: 36.86086916923523
Epoch: 93, Steps: 4 | Train Loss: 0.3085854 Vali Loss: nan Test Loss: 0.2560327
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.617734804586658e-09
Epoch: 94 cost time: 33.20913314819336
Epoch: 94, Steps: 4 | Train Loss: 0.3137583 Vali Loss: nan Test Loss: 0.2560636
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.855961324127991e-09
Epoch: 95 cost time: 33.305213928222656
Epoch: 95, Steps: 4 | Train Loss: 0.3085215 Vali Loss: nan Test Loss: 0.2560212
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.170365191715193e-09
Epoch: 96 cost time: 32.81244421005249
Epoch: 96, Steps: 4 | Train Loss: 0.3085159 Vali Loss: nan Test Loss: 0.2560233
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.5533286725436726e-09
Epoch: 97 cost time: 33.221601724624634
Epoch: 97, Steps: 4 | Train Loss: 0.3106953 Vali Loss: nan Test Loss: 0.2560852
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.997995805289306e-09
Epoch: 98 cost time: 32.255393981933594
Epoch: 98, Steps: 4 | Train Loss: 0.3117704 Vali Loss: nan Test Loss: 0.2560826
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.498196224760375e-09
Epoch: 99 cost time: 33.84248995780945
Epoch: 99, Steps: 4 | Train Loss: 0.3107715 Vali Loss: nan Test Loss: 0.2560823
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.048376602284338e-09
Epoch: 100 cost time: 34.294184923172
Epoch: 100, Steps: 4 | Train Loss: 0.3102677 Vali Loss: nan Test Loss: 0.2561009
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.643538942055904e-09
>>>>>>>testing : 336_28_PatchTST_custom_ftM_sl336_ll48_pl28_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 224
mse:0.2561008632183075, mae:0.3832683861255646, rse:0.32088539004325867
