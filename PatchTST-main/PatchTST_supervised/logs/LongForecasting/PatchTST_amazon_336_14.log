Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='336_14', model='PatchTST', data='custom', root_path='./dataset/', data_path='AMZN_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=14, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=21, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use CPU
>>>>>>>start training : 336_14_PatchTST_custom_ftM_sl336_ll48_pl14_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 532
val 114
test 238
Epoch: 1 cost time: 35.39183306694031
Epoch: 1, Steps: 4 | Train Loss: 1.1163817 Vali Loss: nan Test Loss: 1.6942536
Validation loss decreased (inf --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 35.90073323249817
Epoch: 2, Steps: 4 | Train Loss: 0.8684987 Vali Loss: nan Test Loss: 0.6520451
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 36.21011209487915
Epoch: 3, Steps: 4 | Train Loss: 0.5591897 Vali Loss: nan Test Loss: 0.2161189
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 35.61519694328308
Epoch: 4, Steps: 4 | Train Loss: 0.5958430 Vali Loss: nan Test Loss: 0.1964231
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 35.25429701805115
Epoch: 5, Steps: 4 | Train Loss: 0.6258851 Vali Loss: nan Test Loss: 0.2101720
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 34.526612758636475
Epoch: 6, Steps: 4 | Train Loss: 0.5595734 Vali Loss: nan Test Loss: 0.2124730
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 34.74398684501648
Epoch: 7, Steps: 4 | Train Loss: 0.4745011 Vali Loss: nan Test Loss: 0.2483852
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 36.61820578575134
Epoch: 8, Steps: 4 | Train Loss: 0.4143131 Vali Loss: nan Test Loss: 0.3052380
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 35.49713587760925
Epoch: 9, Steps: 4 | Train Loss: 0.3893250 Vali Loss: nan Test Loss: 0.3503779
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 35.93082404136658
Epoch: 10, Steps: 4 | Train Loss: 0.3847161 Vali Loss: nan Test Loss: 0.3673927
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 35.5923228263855
Epoch: 11, Steps: 4 | Train Loss: 0.3720374 Vali Loss: nan Test Loss: 0.3600850
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 35.14006304740906
Epoch: 12, Steps: 4 | Train Loss: 0.3648919 Vali Loss: nan Test Loss: 0.3372286
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 34.47017288208008
Epoch: 13, Steps: 4 | Train Loss: 0.3478937 Vali Loss: nan Test Loss: 0.3094004
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 36.36551904678345
Epoch: 14, Steps: 4 | Train Loss: 0.3457521 Vali Loss: nan Test Loss: 0.2822776
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 36.05325508117676
Epoch: 15, Steps: 4 | Train Loss: 0.3380939 Vali Loss: nan Test Loss: 0.2594380
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 36.025432109832764
Epoch: 16, Steps: 4 | Train Loss: 0.3197050 Vali Loss: nan Test Loss: 0.2409820
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 37.86422872543335
Epoch: 17, Steps: 4 | Train Loss: 0.3197486 Vali Loss: nan Test Loss: 0.2269439
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 35.67482590675354
Epoch: 18, Steps: 4 | Train Loss: 0.3176325 Vali Loss: nan Test Loss: 0.2169894
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 35.02973699569702
Epoch: 19, Steps: 4 | Train Loss: 0.3117430 Vali Loss: nan Test Loss: 0.2099583
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 35.216338872909546
Epoch: 20, Steps: 4 | Train Loss: 0.3127011 Vali Loss: nan Test Loss: 0.2055317
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 35.14500021934509
Epoch: 21, Steps: 4 | Train Loss: 0.3082495 Vali Loss: nan Test Loss: 0.2028281
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 36.80810499191284
Epoch: 22, Steps: 4 | Train Loss: 0.3064269 Vali Loss: nan Test Loss: 0.2015495
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 35.76177096366882
Epoch: 23, Steps: 4 | Train Loss: 0.3002489 Vali Loss: nan Test Loss: 0.2011083
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 37.80480980873108
Epoch: 24, Steps: 4 | Train Loss: 0.2990000 Vali Loss: nan Test Loss: 0.2009985
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 35.56353211402893
Epoch: 25, Steps: 4 | Train Loss: 0.2964105 Vali Loss: nan Test Loss: 0.2014349
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 35.67182183265686
Epoch: 26, Steps: 4 | Train Loss: 0.3006685 Vali Loss: nan Test Loss: 0.2018048
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 35.691938161849976
Epoch: 27, Steps: 4 | Train Loss: 0.2925387 Vali Loss: nan Test Loss: 0.2022678
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 37.1304087638855
Epoch: 28, Steps: 4 | Train Loss: 0.2910774 Vali Loss: nan Test Loss: 0.2025499
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 37.239063024520874
Epoch: 29, Steps: 4 | Train Loss: 0.2946450 Vali Loss: nan Test Loss: 0.2028325
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 37.17016792297363
Epoch: 30, Steps: 4 | Train Loss: 0.2890370 Vali Loss: nan Test Loss: 0.2029147
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 36.22357177734375
Epoch: 31, Steps: 4 | Train Loss: 0.2919532 Vali Loss: nan Test Loss: 0.2030260
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 38.95533633232117
Epoch: 32, Steps: 4 | Train Loss: 0.2909086 Vali Loss: nan Test Loss: 0.2030101
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 36.55027914047241
Epoch: 33, Steps: 4 | Train Loss: 0.2883464 Vali Loss: nan Test Loss: 0.2030303
Validation loss decreased (nan --> nan).  Saving model ...
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 37.155133962631226
